"use strict";(globalThis.webpackChunkfrontend=globalThis.webpackChunkfrontend||[]).push([[218],{7602:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"Chapter 0: Welcome","items":[{"type":"link","href":"/Humanoid-AI-book/chapter-00-welcome/0.1-welcome","label":"Lesson 0.1: The Goal","docId":"chapter-00-welcome/0.1-welcome","unlisted":false},{"type":"link","href":"/Humanoid-AI-book/chapter-00-welcome/0.2-prerequisites","label":"Lesson 0.2: The Toolbox (Prerequisites)","docId":"chapter-00-welcome/0.2-prerequisites","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Chapter 1: Introduction","items":[{"type":"link","href":"/Humanoid-AI-book/chapter-01-intro/1.1-philosophy","label":"Lesson 1.1: Why Did the Robot Fall?","docId":"chapter-01-intro/1.1-philosophy","unlisted":false},{"type":"link","href":"/Humanoid-AI-book/chapter-01-intro/1.2-hardware-anatomy","label":"Lesson 1.2: The Body of a Physical AI","docId":"chapter-01-intro/1.2-hardware-anatomy","unlisted":false},{"type":"link","href":"/Humanoid-AI-book/chapter-01-intro/1.3-simulation-setup","label":"Lesson 1.3: Entering \\"The Matrix\\"","docId":"chapter-01-intro/1.3-simulation-setup","unlisted":false},{"type":"link","href":"/Humanoid-AI-book/chapter-01-intro/1.4-first-policy","label":"Lesson 1.4: Your First Policy","docId":"chapter-01-intro/1.4-first-policy","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Chapter 2: The Reward Signal","items":[{"type":"link","href":"/Humanoid-AI-book/chapter-02-reward-signal/2.1-what-is-a-reward","label":"2.1 What is a Reward","docId":"chapter-02-reward-signal/2.1-what-is-a-reward","unlisted":false},{"type":"link","href":"/Humanoid-AI-book/chapter-02-reward-signal/2.2-first-reward","label":"2.2 Your First Reward","docId":"chapter-02-reward-signal/2.2-first-reward","unlisted":false},{"type":"link","href":"/Humanoid-AI-book/chapter-02-reward-signal/2.3-reward-shaping","label":"2.3 Reward Shaping","docId":"chapter-02-reward-signal/2.3-reward-shaping","unlisted":false},{"type":"link","href":"/Humanoid-AI-book/chapter-02-reward-signal/2.4-reward-hacking","label":"2.4 Reward Hacking","docId":"chapter-02-reward-signal/2.4-reward-hacking","unlisted":false},{"type":"link","href":"/Humanoid-AI-book/chapter-02-reward-signal/2.5-sparse-vs-dense","label":"Lesson 2.5: Sparse vs. Dense Rewards","docId":"chapter-02-reward-signal/2.5-sparse-vs-dense","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Chapter 3: The Robot\'s Brain: Policies & Value Functions","items":[{"type":"link","href":"/Humanoid-AI-book/chapter-03-policy-and-value/3.1-policy","label":"Lesson 3.1: The Policy","docId":"chapter-03-policy-and-value/3.1-policy","unlisted":false},{"type":"link","href":"/Humanoid-AI-book/chapter-03-policy-and-value/3.2-return","label":"Lesson 3.2: The Return","docId":"chapter-03-policy-and-value/3.2-return","unlisted":false},{"type":"link","href":"/Humanoid-AI-book/chapter-03-policy-and-value/3.3-value-function","label":"Lesson 3.3: Value Function","docId":"chapter-03-policy-and-value/3.3-value-function","unlisted":false}],"collapsed":true,"collapsible":true}]},"docs":{"chapter-00-welcome/0.1-welcome":{"id":"chapter-00-welcome/0.1-welcome","title":"Lesson 0.1: The Goal","description":"Welcome, future Robot Engineer. \ud83d\udc4b","sidebar":"tutorialSidebar"},"chapter-00-welcome/0.2-prerequisites":{"id":"chapter-00-welcome/0.2-prerequisites","title":"Lesson 0.2: The Toolbox (Prerequisites)","description":"Before we start the engines, we need to open our toolbox. Robotics requires three main tools. Let\'s make sure you have them.","sidebar":"tutorialSidebar"},"chapter-01-intro/1.1-philosophy":{"id":"chapter-01-intro/1.1-philosophy","title":"Lesson 1.1: Why Did the Robot Fall?","description":"Welcome to the first lesson of your journey into Physical AI. By the end of this chapter, you will understand the fundamental difference between classical robotics and modern AI-driven approaches, and you\'ll have a clear mental model of how robots learn to move.","sidebar":"tutorialSidebar"},"chapter-01-intro/1.2-hardware-anatomy":{"id":"chapter-01-intro/1.2-hardware-anatomy","title":"Lesson 1.2: The Body of a Physical AI","description":"In this lesson, you\'ll learn the anatomy of a humanoid robot. Understanding the hardware is essential\u2014you can\'t write effective control code if you don\'t know what you\'re controlling.","sidebar":"tutorialSidebar"},"chapter-01-intro/1.3-simulation-setup":{"id":"chapter-01-intro/1.3-simulation-setup","title":"Lesson 1.3: Entering \\"The Matrix\\"","description":"This is the most important lesson in the entire book. By the end, you\'ll have a working robotics simulation environment on your own computer. Once this works, you can run every example in the book.","sidebar":"tutorialSidebar"},"chapter-01-intro/1.4-first-policy":{"id":"chapter-01-intro/1.4-first-policy","title":"Lesson 1.4: Your First Policy","description":"Congratulations! You\'ve made it to the most exciting lesson in this chapter. You\'re about to write code that makes a robot move. It won\'t be graceful\u2014in fact, it will be chaotic\u2014but it\'s the foundation for everything that follows.","sidebar":"tutorialSidebar"},"chapter-02-reward-signal/2.1-what-is-a-reward":{"id":"chapter-02-reward-signal/2.1-what-is-a-reward","title":"Lesson 2.1: What is a Reward: Guiding Robot Behavior with Feedback","description":"In this lesson, you will learn the foundational concept of a reward signal in Reinforcement Learning, understanding how it serves as the primary mechanism for guiding an autonomous robot\'s behavior towards a desired goal.","sidebar":"tutorialSidebar"},"chapter-02-reward-signal/2.2-first-reward":{"id":"chapter-02-reward-signal/2.2-first-reward","title":"Lesson 2.2: Your First Reward: Implementing a Survival Bonus","description":"In this lesson, you will move from theory to practice by implementing your very first reward function for a humanoid robot in a MuJoCo simulation. You will learn how to define a simple \\"survival bonus\\" that encourages the robot to stay upright, integrate this reward into a simulation loop, and understand the practical challenges of translating such a reward from simulation to a real robot.","sidebar":"tutorialSidebar"},"chapter-02-reward-signal/2.3-reward-shaping":{"id":"chapter-02-reward-signal/2.3-reward-shaping","title":"Lesson 2.3: Reward Shaping: Guiding Complex Robot Behaviors","description":"In this lesson, you will delve into reward shaping, a critical technique for designing effective reward functions in Reinforcement Learning. You will learn how to craft more sophisticated reward signals that provide dense, informative feedback to guide a robot towards complex desired behaviors, combining multiple objectives like staying upright, moving forward, and conserving energy.","sidebar":"tutorialSidebar"},"chapter-02-reward-signal/2.4-reward-hacking":{"id":"chapter-02-reward-signal/2.4-reward-hacking","title":"Lesson 2.4: Reward Hacking: The Pitfalls and Perils of Reward Design","description":"In the previous lessons, we\'ve explored the power of reward functions in guiding robot behavior. However, this power comes with a significant challenge: reward hacking. In this lesson, you will learn about the phenomenon where Reinforcement Learning agents find unintended ways to maximize their reward signal, often without achieving the actual goal the human designer intended. We will explore its parallels in human systems, illustrate it with concrete robotics examples, and discuss its severe implications in real-world applications.","sidebar":"tutorialSidebar"},"chapter-02-reward-signal/2.5-sparse-vs-dense":{"id":"chapter-02-reward-signal/2.5-sparse-vs-dense","title":"Lesson 2.5: Sparse vs. Dense Rewards","description":"In this final lesson of Chapter 2, we tackle the fundamental trade-off in reward design: the conflict between guidance and truth.","sidebar":"tutorialSidebar"},"chapter-03-policy-and-value/3.1-policy":{"id":"chapter-03-policy-and-value/3.1-policy","title":"Lesson 3.1: The Policy: How Robots Make Decisions","description":"In this lesson, you will learn what a policy is and why it is the central concept that dictates how an autonomous robot chooses its actions. You will understand the difference between simple \\"reflexes\\" and sophisticated \\"strategies,\\" and implement code that compares these approaches.","sidebar":"tutorialSidebar"},"chapter-03-policy-and-value/3.2-return":{"id":"chapter-03-policy-and-value/3.2-return","title":"Lesson 3.2: The Return: Playing the Long Game","description":"In this lesson, you will learn about the return, the mathematical concept that captures the total value a robot can accumulate over time. You will understand how robots weigh immediate rewards against future ones, and why this \\"long-term thinking\\" is essential for intelligent behavior.","sidebar":"tutorialSidebar"},"chapter-03-policy-and-value/3.3-value-function":{"id":"chapter-03-policy-and-value/3.3-value-function","title":"Lesson 3.3: The Value Function: The Robot\'s Map","description":"In this lesson, you will learn about value functions, the \\"scorecards\\" that tell a robot how good it is to be in a particular state or to take a particular action. You will understand the difference between state-value and action-value functions, grasp the intuition behind the Bellman equation, and visualize value as a heatmap.","sidebar":"tutorialSidebar"}}}}')}}]);