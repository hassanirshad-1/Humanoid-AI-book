"use strict";(globalThis.webpackChunkfrontend=globalThis.webpackChunkfrontend||[]).push([[431],{7600:(s,e,a)=>{a.r(e),a.d(e,{assets:()=>m,contentTitle:()=>r,default:()=>d,frontMatter:()=>t,metadata:()=>n,toc:()=>h});const n=JSON.parse('{"id":"chapter-02-reward-signal/2.5-sparse-vs-dense","title":"Lesson 2.5: Sparse vs. Dense Rewards","description":"In this final lesson of Chapter 2, we tackle the fundamental trade-off in reward design: the conflict between guidance and truth.","source":"@site/docs/chapter-02-reward-signal/2.5-sparse-vs-dense.mdx","sourceDirName":"chapter-02-reward-signal","slug":"/chapter-02-reward-signal/2.5-sparse-vs-dense","permalink":"/Humanoid-AI-book/chapter-02-reward-signal/2.5-sparse-vs-dense","draft":false,"unlisted":false,"editUrl":"https://github.com/hassanirshad-1/Humanoid-AI-book/tree/main/docs/chapter-02-reward-signal/2.5-sparse-vs-dense.mdx","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5,"title":"Lesson 2.5: Sparse vs. Dense Rewards"},"sidebar":"tutorialSidebar","previous":{"title":"2.4 Reward Hacking","permalink":"/Humanoid-AI-book/chapter-02-reward-signal/2.4-reward-hacking"},"next":{"title":"Lesson 3.1: The Policy","permalink":"/Humanoid-AI-book/chapter-03-policy-and-value/3.1-policy"}}');var l=a(4848),i=a(8453);const t={sidebar_position:5,title:"Lesson 2.5: Sparse vs. Dense Rewards"},r="Lesson 2.5: Sparse vs. Dense Rewards",m={},h=[{value:"The Concrete Hook: The Maze",id:"the-concrete-hook-the-maze",level:2},{value:"The Intuition: Teaching a Dog",id:"the-intuition-teaching-a-dog",level:2},{value:"The Formalism: Mathematical Definitions",id:"the-formalism-mathematical-definitions",level:2},{value:"Sparse Reward",id:"sparse-reward",level:3},{value:"Dense Reward",id:"dense-reward",level:3},{value:"The Code: Comparing Implementations",id:"the-code-comparing-implementations",level:2},{value:"The Simulation: The Local Optimum Trap",id:"the-simulation-the-local-optimum-trap",level:2},{value:"The Reality Check (Sim-to-Real)",id:"the-reality-check-sim-to-real",level:2},{value:"Knowledge Check \u2713",id:"knowledge-check-",level:2},{value:"Try This",id:"try-this",level:2},{value:"Further Reading",id:"further-reading",level:2}];function c(s){const e={annotation:"annotation",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",math:"math",mi:"mi",mn:"mn",mo:"mo",mrow:"mrow",mstyle:"mstyle",msub:"msub",mtable:"mtable",mtd:"mtd",mtext:"mtext",mtr:"mtr",ol:"ol",p:"p",pre:"pre",semantics:"semantics",span:"span",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...s.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(e.header,{children:(0,l.jsx)(e.h1,{id:"lesson-25-sparse-vs-dense-rewards",children:"Lesson 2.5: Sparse vs. Dense Rewards"})}),"\n",(0,l.jsxs)(e.p,{children:["In this final lesson of Chapter 2, we tackle the fundamental trade-off in reward design: the conflict between ",(0,l.jsx)(e.strong,{children:"guidance"})," and ",(0,l.jsx)(e.strong,{children:"truth"}),"."]}),"\n",(0,l.jsx)(e.hr,{}),"\n",(0,l.jsx)(e.h2,{id:"the-concrete-hook-the-maze",children:"The Concrete Hook: The Maze"}),"\n",(0,l.jsx)(e.p,{children:"Imagine you are dropped into a giant, complex maze blindfolded. You need to find the exit."}),"\n",(0,l.jsxs)(e.p,{children:[(0,l.jsx)(e.strong,{children:"Scenario A"}),": You only get a signal when you actually solve the maze. You wander for hours, days, maybe years, hearing nothing. Finally, if you stumble out, a bell rings.\r\n",(0,l.jsx)(e.strong,{children:"Scenario B"}),': At every single step, a guide whispers "Warmer" or "Colder" depending on whether you moved closer to the exit.']}),"\n",(0,l.jsxs)(e.p,{children:["Scenario A is a ",(0,l.jsx)(e.strong,{children:"Sparse Reward"}),". It's brutally hard, but if the bell rings, you know you succeeded.\r\nScenario B is a ",(0,l.jsx)(e.strong,{children:"Dense Reward"}),". It's much easier to follow, but what if the \"Warmer\" path leads you to a dead-end right next to the exit wall? You might get stuck there, thinking you're close, while the true path required backtracking."]}),"\n",(0,l.jsx)(e.p,{children:"In robotics, we constantly balance these two approaches."}),"\n",(0,l.jsx)(e.hr,{}),"\n",(0,l.jsx)(e.h2,{id:"the-intuition-teaching-a-dog",children:"The Intuition: Teaching a Dog"}),"\n",(0,l.jsx)(e.p,{children:"Think back to training a dog."}),"\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsxs)(e.li,{children:[(0,l.jsx)(e.strong,{children:"Sparse"}),': You say "Sit." The dog does nothing. It barks. It jumps. It runs in circles. You wait. 10 minutes later, it accidentally sits. You click and treat. The dog has no idea ',(0,l.jsx)(e.em,{children:"which"})," of the last 100 things it did earned the treat. This is the ",(0,l.jsx)(e.strong,{children:"Credit Assignment Problem"}),"."]}),"\n",(0,l.jsxs)(e.li,{children:[(0,l.jsx)(e.strong,{children:"Dense"}),': You use "shaping." First, you reward looking at the floor. Then lowering the hips slightly. Then lowering them more. You guide the behavior step-by-step.']}),"\n"]}),"\n",(0,l.jsxs)(e.p,{children:["For humanoid robots, ",(0,l.jsx)(e.strong,{children:"Sparse Rewards"}),' represent the true goal (e.g., "don\'t fall"), while ',(0,l.jsx)(e.strong,{children:"Dense Rewards"}),' provide the hints needed to learn complex movements (e.g., "move feet forward," "keep torso upright").']}),"\n",(0,l.jsx)(e.hr,{}),"\n",(0,l.jsx)(e.h2,{id:"the-formalism-mathematical-definitions",children:"The Formalism: Mathematical Definitions"}),"\n",(0,l.jsxs)(e.p,{children:["We can define these mathematically based on the non-zero density of the reward signal ",(0,l.jsxs)(e.span,{className:"katex",children:[(0,l.jsx)(e.span,{className:"katex-mathml",children:(0,l.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,l.jsxs)(e.semantics,{children:[(0,l.jsx)(e.mrow,{children:(0,l.jsxs)(e.msub,{children:[(0,l.jsx)(e.mi,{children:"r"}),(0,l.jsx)(e.mi,{children:"t"})]})}),(0,l.jsx)(e.annotation,{encoding:"application/x-tex",children:"r_t"})]})})}),(0,l.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,l.jsxs)(e.span,{className:"base",children:[(0,l.jsx)(e.span,{className:"strut",style:{height:"0.5806em",verticalAlign:"-0.15em"}}),(0,l.jsxs)(e.span,{className:"mord",children:[(0,l.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.02778em"},children:"r"}),(0,l.jsx)(e.span,{className:"msupsub",children:(0,l.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,l.jsxs)(e.span,{className:"vlist-r",children:[(0,l.jsx)(e.span,{className:"vlist",style:{height:"0.2806em"},children:(0,l.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"-0.0278em",marginRight:"0.05em"},children:[(0,l.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,l.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,l.jsx)(e.span,{className:"mord mathnormal mtight",children:"t"})})]})}),(0,l.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,l.jsx)(e.span,{className:"vlist-r",children:(0,l.jsx)(e.span,{className:"vlist",style:{height:"0.15em"},children:(0,l.jsx)(e.span,{})})})]})})]})]})})]}),"."]}),"\n",(0,l.jsx)(e.h3,{id:"sparse-reward",children:"Sparse Reward"}),"\n",(0,l.jsxs)(e.p,{children:["A sparse reward is zero for almost all states, except for a specific subset of goal states ",(0,l.jsxs)(e.span,{className:"katex",children:[(0,l.jsx)(e.span,{className:"katex-mathml",children:(0,l.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,l.jsxs)(e.semantics,{children:[(0,l.jsx)(e.mrow,{children:(0,l.jsxs)(e.msub,{children:[(0,l.jsx)(e.mi,{children:"S"}),(0,l.jsxs)(e.mrow,{children:[(0,l.jsx)(e.mi,{children:"g"}),(0,l.jsx)(e.mi,{children:"o"}),(0,l.jsx)(e.mi,{children:"a"}),(0,l.jsx)(e.mi,{children:"l"})]})]})}),(0,l.jsx)(e.annotation,{encoding:"application/x-tex",children:"S_{goal}"})]})})}),(0,l.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,l.jsxs)(e.span,{className:"base",children:[(0,l.jsx)(e.span,{className:"strut",style:{height:"0.9694em",verticalAlign:"-0.2861em"}}),(0,l.jsxs)(e.span,{className:"mord",children:[(0,l.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.05764em"},children:"S"}),(0,l.jsx)(e.span,{className:"msupsub",children:(0,l.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,l.jsxs)(e.span,{className:"vlist-r",children:[(0,l.jsx)(e.span,{className:"vlist",style:{height:"0.3361em"},children:(0,l.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"-0.0576em",marginRight:"0.05em"},children:[(0,l.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,l.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,l.jsxs)(e.span,{className:"mord mtight",children:[(0,l.jsx)(e.span,{className:"mord mathnormal mtight",style:{marginRight:"0.03588em"},children:"g"}),(0,l.jsx)(e.span,{className:"mord mathnormal mtight",children:"o"}),(0,l.jsx)(e.span,{className:"mord mathnormal mtight",children:"a"}),(0,l.jsx)(e.span,{className:"mord mathnormal mtight",style:{marginRight:"0.01968em"},children:"l"})]})})]})}),(0,l.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,l.jsx)(e.span,{className:"vlist-r",children:(0,l.jsx)(e.span,{className:"vlist",style:{height:"0.2861em"},children:(0,l.jsx)(e.span,{})})})]})})]})]})})]}),"."]}),"\n",(0,l.jsx)(e.span,{className:"katex-display",children:(0,l.jsxs)(e.span,{className:"katex",children:[(0,l.jsx)(e.span,{className:"katex-mathml",children:(0,l.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block",children:(0,l.jsxs)(e.semantics,{children:[(0,l.jsxs)(e.mrow,{children:[(0,l.jsxs)(e.msub,{children:[(0,l.jsx)(e.mi,{children:"r"}),(0,l.jsx)(e.mi,{children:"t"})]}),(0,l.jsx)(e.mo,{children:"="}),(0,l.jsxs)(e.mrow,{children:[(0,l.jsx)(e.mo,{fence:"true",children:"{"}),(0,l.jsxs)(e.mtable,{rowspacing:"0.36em",columnalign:"left left",columnspacing:"1em",children:[(0,l.jsxs)(e.mtr,{children:[(0,l.jsx)(e.mtd,{children:(0,l.jsx)(e.mstyle,{scriptlevel:"0",displaystyle:"false",children:(0,l.jsx)(e.mn,{children:"1"})})}),(0,l.jsx)(e.mtd,{children:(0,l.jsx)(e.mstyle,{scriptlevel:"0",displaystyle:"false",children:(0,l.jsxs)(e.mrow,{children:[(0,l.jsx)(e.mtext,{children:"if\xa0"}),(0,l.jsxs)(e.msub,{children:[(0,l.jsx)(e.mi,{children:"s"}),(0,l.jsx)(e.mi,{children:"t"})]}),(0,l.jsx)(e.mo,{children:"\u2208"}),(0,l.jsxs)(e.msub,{children:[(0,l.jsx)(e.mi,{children:"S"}),(0,l.jsxs)(e.mrow,{children:[(0,l.jsx)(e.mi,{children:"g"}),(0,l.jsx)(e.mi,{children:"o"}),(0,l.jsx)(e.mi,{children:"a"}),(0,l.jsx)(e.mi,{children:"l"})]})]})]})})})]}),(0,l.jsxs)(e.mtr,{children:[(0,l.jsx)(e.mtd,{children:(0,l.jsx)(e.mstyle,{scriptlevel:"0",displaystyle:"false",children:(0,l.jsx)(e.mn,{children:"0"})})}),(0,l.jsx)(e.mtd,{children:(0,l.jsx)(e.mstyle,{scriptlevel:"0",displaystyle:"false",children:(0,l.jsx)(e.mtext,{children:"otherwise"})})})]})]})]})]}),(0,l.jsx)(e.annotation,{encoding:"application/x-tex",children:"r_t = \\begin{cases} \n1 & \\text{if } s_t \\in S_{goal} \\\\\n0 & \\text{otherwise}\n\\end{cases}"})]})})}),(0,l.jsxs)(e.span,{className:"katex-html","aria-hidden":"true",children:[(0,l.jsxs)(e.span,{className:"base",children:[(0,l.jsx)(e.span,{className:"strut",style:{height:"0.5806em",verticalAlign:"-0.15em"}}),(0,l.jsxs)(e.span,{className:"mord",children:[(0,l.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.02778em"},children:"r"}),(0,l.jsx)(e.span,{className:"msupsub",children:(0,l.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,l.jsxs)(e.span,{className:"vlist-r",children:[(0,l.jsx)(e.span,{className:"vlist",style:{height:"0.2806em"},children:(0,l.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"-0.0278em",marginRight:"0.05em"},children:[(0,l.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,l.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,l.jsx)(e.span,{className:"mord mathnormal mtight",children:"t"})})]})}),(0,l.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,l.jsx)(e.span,{className:"vlist-r",children:(0,l.jsx)(e.span,{className:"vlist",style:{height:"0.15em"},children:(0,l.jsx)(e.span,{})})})]})})]}),(0,l.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,l.jsx)(e.span,{className:"mrel",children:"="}),(0,l.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,l.jsxs)(e.span,{className:"base",children:[(0,l.jsx)(e.span,{className:"strut",style:{height:"3em",verticalAlign:"-1.25em"}}),(0,l.jsxs)(e.span,{className:"minner",children:[(0,l.jsx)(e.span,{className:"mopen delimcenter",style:{top:"0em"},children:(0,l.jsx)(e.span,{className:"delimsizing size4",children:"{"})}),(0,l.jsx)(e.span,{className:"mord",children:(0,l.jsxs)(e.span,{className:"mtable",children:[(0,l.jsx)(e.span,{className:"col-align-l",children:(0,l.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,l.jsxs)(e.span,{className:"vlist-r",children:[(0,l.jsxs)(e.span,{className:"vlist",style:{height:"1.69em"},children:[(0,l.jsxs)(e.span,{style:{top:"-3.69em"},children:[(0,l.jsx)(e.span,{className:"pstrut",style:{height:"3.008em"}}),(0,l.jsx)(e.span,{className:"mord",children:(0,l.jsx)(e.span,{className:"mord",children:"1"})})]}),(0,l.jsxs)(e.span,{style:{top:"-2.25em"},children:[(0,l.jsx)(e.span,{className:"pstrut",style:{height:"3.008em"}}),(0,l.jsx)(e.span,{className:"mord",children:(0,l.jsx)(e.span,{className:"mord",children:"0"})})]})]}),(0,l.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,l.jsx)(e.span,{className:"vlist-r",children:(0,l.jsx)(e.span,{className:"vlist",style:{height:"1.19em"},children:(0,l.jsx)(e.span,{})})})]})}),(0,l.jsx)(e.span,{className:"arraycolsep",style:{width:"1em"}}),(0,l.jsx)(e.span,{className:"col-align-l",children:(0,l.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,l.jsxs)(e.span,{className:"vlist-r",children:[(0,l.jsxs)(e.span,{className:"vlist",style:{height:"1.69em"},children:[(0,l.jsxs)(e.span,{style:{top:"-3.69em"},children:[(0,l.jsx)(e.span,{className:"pstrut",style:{height:"3.008em"}}),(0,l.jsxs)(e.span,{className:"mord",children:[(0,l.jsx)(e.span,{className:"mord text",children:(0,l.jsx)(e.span,{className:"mord",children:"if\xa0"})}),(0,l.jsxs)(e.span,{className:"mord",children:[(0,l.jsx)(e.span,{className:"mord mathnormal",children:"s"}),(0,l.jsx)(e.span,{className:"msupsub",children:(0,l.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,l.jsxs)(e.span,{className:"vlist-r",children:[(0,l.jsx)(e.span,{className:"vlist",style:{height:"0.2806em"},children:(0,l.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,l.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,l.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,l.jsx)(e.span,{className:"mord mathnormal mtight",children:"t"})})]})}),(0,l.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,l.jsx)(e.span,{className:"vlist-r",children:(0,l.jsx)(e.span,{className:"vlist",style:{height:"0.15em"},children:(0,l.jsx)(e.span,{})})})]})})]}),(0,l.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,l.jsx)(e.span,{className:"mrel",children:"\u2208"}),(0,l.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,l.jsxs)(e.span,{className:"mord",children:[(0,l.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.05764em"},children:"S"}),(0,l.jsx)(e.span,{className:"msupsub",children:(0,l.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,l.jsxs)(e.span,{className:"vlist-r",children:[(0,l.jsx)(e.span,{className:"vlist",style:{height:"0.3361em"},children:(0,l.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"-0.0576em",marginRight:"0.05em"},children:[(0,l.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,l.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,l.jsxs)(e.span,{className:"mord mtight",children:[(0,l.jsx)(e.span,{className:"mord mathnormal mtight",style:{marginRight:"0.03588em"},children:"g"}),(0,l.jsx)(e.span,{className:"mord mathnormal mtight",children:"o"}),(0,l.jsx)(e.span,{className:"mord mathnormal mtight",children:"a"}),(0,l.jsx)(e.span,{className:"mord mathnormal mtight",style:{marginRight:"0.01968em"},children:"l"})]})})]})}),(0,l.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,l.jsx)(e.span,{className:"vlist-r",children:(0,l.jsx)(e.span,{className:"vlist",style:{height:"0.2861em"},children:(0,l.jsx)(e.span,{})})})]})})]})]})]}),(0,l.jsxs)(e.span,{style:{top:"-2.25em"},children:[(0,l.jsx)(e.span,{className:"pstrut",style:{height:"3.008em"}}),(0,l.jsx)(e.span,{className:"mord",children:(0,l.jsx)(e.span,{className:"mord text",children:(0,l.jsx)(e.span,{className:"mord",children:"otherwise"})})})]})]}),(0,l.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,l.jsx)(e.span,{className:"vlist-r",children:(0,l.jsx)(e.span,{className:"vlist",style:{height:"1.19em"},children:(0,l.jsx)(e.span,{})})})]})})]})}),(0,l.jsx)(e.span,{className:"mclose nulldelimiter"})]})]})]})]})}),"\n",(0,l.jsx)(e.p,{children:'This is the "purest" form of specifying a task. There is no ambiguity.'}),"\n",(0,l.jsx)(e.h3,{id:"dense-reward",children:"Dense Reward"}),"\n",(0,l.jsx)(e.p,{children:"A dense reward provides a non-zero signal at almost every timestep, usually proportional to progress."}),"\n",(0,l.jsx)(e.span,{className:"katex-display",children:(0,l.jsxs)(e.span,{className:"katex",children:[(0,l.jsx)(e.span,{className:"katex-mathml",children:(0,l.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block",children:(0,l.jsxs)(e.semantics,{children:[(0,l.jsxs)(e.mrow,{children:[(0,l.jsxs)(e.msub,{children:[(0,l.jsx)(e.mi,{children:"r"}),(0,l.jsx)(e.mi,{children:"t"})]}),(0,l.jsx)(e.mo,{children:"="}),(0,l.jsx)(e.mtext,{children:"progress"}),(0,l.jsx)(e.mo,{stretchy:"false",children:"("}),(0,l.jsxs)(e.msub,{children:[(0,l.jsx)(e.mi,{children:"s"}),(0,l.jsx)(e.mi,{children:"t"})]}),(0,l.jsx)(e.mo,{separator:"true",children:","}),(0,l.jsxs)(e.msub,{children:[(0,l.jsx)(e.mi,{children:"s"}),(0,l.jsxs)(e.mrow,{children:[(0,l.jsx)(e.mi,{children:"g"}),(0,l.jsx)(e.mi,{children:"o"}),(0,l.jsx)(e.mi,{children:"a"}),(0,l.jsx)(e.mi,{children:"l"})]})]}),(0,l.jsx)(e.mo,{stretchy:"false",children:")"}),(0,l.jsx)(e.mo,{children:"\u2212"}),(0,l.jsx)(e.mtext,{children:"cost"}),(0,l.jsx)(e.mo,{stretchy:"false",children:"("}),(0,l.jsxs)(e.msub,{children:[(0,l.jsx)(e.mi,{children:"a"}),(0,l.jsx)(e.mi,{children:"t"})]}),(0,l.jsx)(e.mo,{stretchy:"false",children:")"})]}),(0,l.jsx)(e.annotation,{encoding:"application/x-tex",children:"r_t = \\text{progress}(s_t, s_{goal}) - \\text{cost}(a_t)"})]})})}),(0,l.jsxs)(e.span,{className:"katex-html","aria-hidden":"true",children:[(0,l.jsxs)(e.span,{className:"base",children:[(0,l.jsx)(e.span,{className:"strut",style:{height:"0.5806em",verticalAlign:"-0.15em"}}),(0,l.jsxs)(e.span,{className:"mord",children:[(0,l.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.02778em"},children:"r"}),(0,l.jsx)(e.span,{className:"msupsub",children:(0,l.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,l.jsxs)(e.span,{className:"vlist-r",children:[(0,l.jsx)(e.span,{className:"vlist",style:{height:"0.2806em"},children:(0,l.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"-0.0278em",marginRight:"0.05em"},children:[(0,l.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,l.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,l.jsx)(e.span,{className:"mord mathnormal mtight",children:"t"})})]})}),(0,l.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,l.jsx)(e.span,{className:"vlist-r",children:(0,l.jsx)(e.span,{className:"vlist",style:{height:"0.15em"},children:(0,l.jsx)(e.span,{})})})]})})]}),(0,l.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,l.jsx)(e.span,{className:"mrel",children:"="}),(0,l.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,l.jsxs)(e.span,{className:"base",children:[(0,l.jsx)(e.span,{className:"strut",style:{height:"1.0361em",verticalAlign:"-0.2861em"}}),(0,l.jsx)(e.span,{className:"mord text",children:(0,l.jsx)(e.span,{className:"mord",children:"progress"})}),(0,l.jsx)(e.span,{className:"mopen",children:"("}),(0,l.jsxs)(e.span,{className:"mord",children:[(0,l.jsx)(e.span,{className:"mord mathnormal",children:"s"}),(0,l.jsx)(e.span,{className:"msupsub",children:(0,l.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,l.jsxs)(e.span,{className:"vlist-r",children:[(0,l.jsx)(e.span,{className:"vlist",style:{height:"0.2806em"},children:(0,l.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,l.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,l.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,l.jsx)(e.span,{className:"mord mathnormal mtight",children:"t"})})]})}),(0,l.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,l.jsx)(e.span,{className:"vlist-r",children:(0,l.jsx)(e.span,{className:"vlist",style:{height:"0.15em"},children:(0,l.jsx)(e.span,{})})})]})})]}),(0,l.jsx)(e.span,{className:"mpunct",children:","}),(0,l.jsx)(e.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,l.jsxs)(e.span,{className:"mord",children:[(0,l.jsx)(e.span,{className:"mord mathnormal",children:"s"}),(0,l.jsx)(e.span,{className:"msupsub",children:(0,l.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,l.jsxs)(e.span,{className:"vlist-r",children:[(0,l.jsx)(e.span,{className:"vlist",style:{height:"0.3361em"},children:(0,l.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,l.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,l.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,l.jsxs)(e.span,{className:"mord mtight",children:[(0,l.jsx)(e.span,{className:"mord mathnormal mtight",style:{marginRight:"0.03588em"},children:"g"}),(0,l.jsx)(e.span,{className:"mord mathnormal mtight",children:"o"}),(0,l.jsx)(e.span,{className:"mord mathnormal mtight",children:"a"}),(0,l.jsx)(e.span,{className:"mord mathnormal mtight",style:{marginRight:"0.01968em"},children:"l"})]})})]})}),(0,l.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,l.jsx)(e.span,{className:"vlist-r",children:(0,l.jsx)(e.span,{className:"vlist",style:{height:"0.2861em"},children:(0,l.jsx)(e.span,{})})})]})})]}),(0,l.jsx)(e.span,{className:"mclose",children:")"}),(0,l.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,l.jsx)(e.span,{className:"mbin",children:"\u2212"}),(0,l.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,l.jsxs)(e.span,{className:"base",children:[(0,l.jsx)(e.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,l.jsx)(e.span,{className:"mord text",children:(0,l.jsx)(e.span,{className:"mord",children:"cost"})}),(0,l.jsx)(e.span,{className:"mopen",children:"("}),(0,l.jsxs)(e.span,{className:"mord",children:[(0,l.jsx)(e.span,{className:"mord mathnormal",children:"a"}),(0,l.jsx)(e.span,{className:"msupsub",children:(0,l.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,l.jsxs)(e.span,{className:"vlist-r",children:[(0,l.jsx)(e.span,{className:"vlist",style:{height:"0.2806em"},children:(0,l.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,l.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,l.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,l.jsx)(e.span,{className:"mord mathnormal mtight",children:"t"})})]})}),(0,l.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,l.jsx)(e.span,{className:"vlist-r",children:(0,l.jsx)(e.span,{className:"vlist",style:{height:"0.15em"},children:(0,l.jsx)(e.span,{})})})]})})]}),(0,l.jsx)(e.span,{className:"mclose",children:")"})]})]})]})}),"\n",(0,l.jsxs)(e.p,{children:["For example, measuring the negative distance to the target: ",(0,l.jsxs)(e.span,{className:"katex",children:[(0,l.jsx)(e.span,{className:"katex-mathml",children:(0,l.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,l.jsxs)(e.semantics,{children:[(0,l.jsxs)(e.mrow,{children:[(0,l.jsxs)(e.msub,{children:[(0,l.jsx)(e.mi,{children:"r"}),(0,l.jsx)(e.mi,{children:"t"})]}),(0,l.jsx)(e.mo,{children:"="}),(0,l.jsx)(e.mo,{children:"\u2212"}),(0,l.jsx)(e.mi,{mathvariant:"normal",children:"\u2223"}),(0,l.jsx)(e.mi,{mathvariant:"normal",children:"\u2223"}),(0,l.jsxs)(e.msub,{children:[(0,l.jsx)(e.mi,{children:"s"}),(0,l.jsx)(e.mi,{children:"t"})]}),(0,l.jsx)(e.mo,{children:"\u2212"}),(0,l.jsxs)(e.msub,{children:[(0,l.jsx)(e.mi,{children:"s"}),(0,l.jsxs)(e.mrow,{children:[(0,l.jsx)(e.mi,{children:"g"}),(0,l.jsx)(e.mi,{children:"o"}),(0,l.jsx)(e.mi,{children:"a"}),(0,l.jsx)(e.mi,{children:"l"})]})]}),(0,l.jsx)(e.mi,{mathvariant:"normal",children:"\u2223"}),(0,l.jsx)(e.mi,{mathvariant:"normal",children:"\u2223"})]}),(0,l.jsx)(e.annotation,{encoding:"application/x-tex",children:"r_t = -||s_t - s_{goal}||"})]})})}),(0,l.jsxs)(e.span,{className:"katex-html","aria-hidden":"true",children:[(0,l.jsxs)(e.span,{className:"base",children:[(0,l.jsx)(e.span,{className:"strut",style:{height:"0.5806em",verticalAlign:"-0.15em"}}),(0,l.jsxs)(e.span,{className:"mord",children:[(0,l.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.02778em"},children:"r"}),(0,l.jsx)(e.span,{className:"msupsub",children:(0,l.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,l.jsxs)(e.span,{className:"vlist-r",children:[(0,l.jsx)(e.span,{className:"vlist",style:{height:"0.2806em"},children:(0,l.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"-0.0278em",marginRight:"0.05em"},children:[(0,l.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,l.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,l.jsx)(e.span,{className:"mord mathnormal mtight",children:"t"})})]})}),(0,l.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,l.jsx)(e.span,{className:"vlist-r",children:(0,l.jsx)(e.span,{className:"vlist",style:{height:"0.15em"},children:(0,l.jsx)(e.span,{})})})]})})]}),(0,l.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,l.jsx)(e.span,{className:"mrel",children:"="}),(0,l.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,l.jsxs)(e.span,{className:"base",children:[(0,l.jsx)(e.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,l.jsx)(e.span,{className:"mord",children:"\u2212"}),(0,l.jsx)(e.span,{className:"mord",children:"\u2223\u2223"}),(0,l.jsxs)(e.span,{className:"mord",children:[(0,l.jsx)(e.span,{className:"mord mathnormal",children:"s"}),(0,l.jsx)(e.span,{className:"msupsub",children:(0,l.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,l.jsxs)(e.span,{className:"vlist-r",children:[(0,l.jsx)(e.span,{className:"vlist",style:{height:"0.2806em"},children:(0,l.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,l.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,l.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,l.jsx)(e.span,{className:"mord mathnormal mtight",children:"t"})})]})}),(0,l.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,l.jsx)(e.span,{className:"vlist-r",children:(0,l.jsx)(e.span,{className:"vlist",style:{height:"0.15em"},children:(0,l.jsx)(e.span,{})})})]})})]}),(0,l.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,l.jsx)(e.span,{className:"mbin",children:"\u2212"}),(0,l.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,l.jsxs)(e.span,{className:"base",children:[(0,l.jsx)(e.span,{className:"strut",style:{height:"1.0361em",verticalAlign:"-0.2861em"}}),(0,l.jsxs)(e.span,{className:"mord",children:[(0,l.jsx)(e.span,{className:"mord mathnormal",children:"s"}),(0,l.jsx)(e.span,{className:"msupsub",children:(0,l.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,l.jsxs)(e.span,{className:"vlist-r",children:[(0,l.jsx)(e.span,{className:"vlist",style:{height:"0.3361em"},children:(0,l.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,l.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,l.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,l.jsxs)(e.span,{className:"mord mtight",children:[(0,l.jsx)(e.span,{className:"mord mathnormal mtight",style:{marginRight:"0.03588em"},children:"g"}),(0,l.jsx)(e.span,{className:"mord mathnormal mtight",children:"o"}),(0,l.jsx)(e.span,{className:"mord mathnormal mtight",children:"a"}),(0,l.jsx)(e.span,{className:"mord mathnormal mtight",style:{marginRight:"0.01968em"},children:"l"})]})})]})}),(0,l.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,l.jsx)(e.span,{className:"vlist-r",children:(0,l.jsx)(e.span,{className:"vlist",style:{height:"0.2861em"},children:(0,l.jsx)(e.span,{})})})]})})]}),(0,l.jsx)(e.span,{className:"mord",children:"\u2223\u2223"})]})]})]}),"."]}),"\n",(0,l.jsx)(e.hr,{}),"\n",(0,l.jsx)(e.h2,{id:"the-code-comparing-implementations",children:"The Code: Comparing Implementations"}),"\n",(0,l.jsxs)(e.p,{children:["Let's implement both for a hypothetical task: moving the robot to a target position ",(0,l.jsxs)(e.span,{className:"katex",children:[(0,l.jsx)(e.span,{className:"katex-mathml",children:(0,l.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,l.jsxs)(e.semantics,{children:[(0,l.jsxs)(e.mrow,{children:[(0,l.jsx)(e.mi,{children:"x"}),(0,l.jsx)(e.mo,{children:"="}),(0,l.jsx)(e.mn,{children:"10"})]}),(0,l.jsx)(e.annotation,{encoding:"application/x-tex",children:"x=10"})]})})}),(0,l.jsxs)(e.span,{className:"katex-html","aria-hidden":"true",children:[(0,l.jsxs)(e.span,{className:"base",children:[(0,l.jsx)(e.span,{className:"strut",style:{height:"0.4306em"}}),(0,l.jsx)(e.span,{className:"mord mathnormal",children:"x"}),(0,l.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,l.jsx)(e.span,{className:"mrel",children:"="}),(0,l.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,l.jsxs)(e.span,{className:"base",children:[(0,l.jsx)(e.span,{className:"strut",style:{height:"0.6444em"}}),(0,l.jsx)(e.span,{className:"mord",children:"10"})]})]})]})," meters."]}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:'import numpy as np\r\n\r\ndef calculate_sparse_reward(robot_x, target_x=10.0, threshold=0.5):\r\n    """\r\n    Returns 1.0 ONLY if within threshold of the target.\r\n    Otherwise returns 0.0.\r\n    """\r\n    distance = np.abs(robot_x - target_x)\r\n    if distance < threshold:\r\n        return 1.0  # The "Bell Rings"\r\n    else:\r\n        return 0.0  # Silence\r\n\r\ndef calculate_dense_reward(robot_x, target_x=10.0):\r\n    """\r\n    Returns a value proportional to how close we are.\r\n    Higher (less negative) is better.\r\n    """\r\n    distance = np.abs(robot_x - target_x)\r\n    \r\n    # Simple dense reward: negative distance\r\n    reward = -distance\r\n    \r\n    # Normalized to be positive (0 to 1) for easier interpretation\r\n    # (assuming max distance is ~20m)\r\n    # reward = 1.0 - (distance / 20.0) \r\n    \r\n    return reward\n'})}),"\n",(0,l.jsxs)(e.p,{children:["In ",(0,l.jsx)(e.code,{children:"action_loop.py"}),", if we used the sparse reward, our random robot would print ",(0,l.jsx)(e.code,{children:"Reward: 0.0"})," for millions of steps. With the dense reward, it would see ",(0,l.jsx)(e.code,{children:"Reward: -10.0"}),", ",(0,l.jsx)(e.code,{children:"Reward: -9.9"}),"... providing immediate feedback on whether a jittery movement helped or hurt."]}),"\n",(0,l.jsx)(e.hr,{}),"\n",(0,l.jsx)(e.h2,{id:"the-simulation-the-local-optimum-trap",children:"The Simulation: The Local Optimum Trap"}),"\n",(0,l.jsx)(e.p,{children:"What happens if we strictly follow dense rewards?"}),"\n",(0,l.jsx)(e.p,{children:"Imagine our Unitree G1 robot is standing in front of a wall, and the target is on the other side."}),"\n",(0,l.jsxs)(e.ol,{children:["\n",(0,l.jsxs)(e.li,{children:[(0,l.jsx)(e.strong,{children:"Dense Reward"}),": The robot walks ",(0,l.jsx)(e.em,{children:"into"})," the wall and keeps pushing. Why? Because that is the physical point closest to the target. It gets stuck in a ",(0,l.jsx)(e.strong,{children:"Local Optimum"}),"."]}),"\n",(0,l.jsxs)(e.li,{children:[(0,l.jsx)(e.strong,{children:"Sparse Reward"}),": The robot wanders randomly. It eventually (after a very long time) walks ",(0,l.jsx)(e.em,{children:"around"})," the wall and hits the target."]}),"\n"]}),"\n",(0,l.jsxs)(e.p,{children:["In practice, we often ",(0,l.jsx)(e.strong,{children:"combine"})," them: use dense rewards to learn locomotion skills (walking), but sparse rewards for high-level logic (navigation)."]}),"\n",(0,l.jsx)(e.hr,{}),"\n",(0,l.jsx)(e.h2,{id:"the-reality-check-sim-to-real",children:"The Reality Check (Sim-to-Real)"}),"\n",(0,l.jsxs)(e.p,{children:["There is a major catch with Dense Rewards in the real world: ",(0,l.jsx)(e.strong,{children:"How do you measure them?"})]}),"\n",(0,l.jsxs)(e.table,{children:[(0,l.jsx)(e.thead,{children:(0,l.jsxs)(e.tr,{children:[(0,l.jsx)(e.th,{style:{textAlign:"left"},children:"Reward Type"}),(0,l.jsx)(e.th,{style:{textAlign:"left"},children:"Simulation Requirement"}),(0,l.jsx)(e.th,{style:{textAlign:"left"},children:"Real World Requirement"})]})}),(0,l.jsxs)(e.tbody,{children:[(0,l.jsxs)(e.tr,{children:[(0,l.jsxs)(e.td,{style:{textAlign:"left"},children:[(0,l.jsx)(e.strong,{children:"Sparse"})," (Did you fall?)"]}),(0,l.jsx)(e.td,{style:{textAlign:"left"},children:"IMU (Orientation)"}),(0,l.jsx)(e.td,{style:{textAlign:"left"},children:"IMU (Cheap, built-in)"})]}),(0,l.jsxs)(e.tr,{children:[(0,l.jsxs)(e.td,{style:{textAlign:"left"},children:[(0,l.jsx)(e.strong,{children:"Dense"})," (Velocity tracking)"]}),(0,l.jsx)(e.td,{style:{textAlign:"left"},children:"Perfect State Knowledge"}),(0,l.jsx)(e.td,{style:{textAlign:"left"},children:"GPS / Motion Capture System"})]})]})]}),"\n",(0,l.jsxs)(e.p,{children:['To calculate a dense "move forward" reward in Sim, we just ask the physics engine "what is my x-velocity?".\r\nTo do it in Real Life, the robot needs to ',(0,l.jsx)(e.em,{children:"know"})," its speed. If its feet are slipping on ice, its internal sensors might say \"I'm running fast!\" (wheels/joints spinning) while it's actually standing still."]}),"\n",(0,l.jsxs)(e.p,{children:[(0,l.jsx)(e.strong,{children:"Sim-to-Real Tip"}),": If your dense reward relies on information you can't measure accurately on the real robot (like exact global position), you must train a ",(0,l.jsx)(e.strong,{children:"state estimator"})," or use domain randomization (Chapter 4) to handle the mismatch."]}),"\n",(0,l.jsx)(e.hr,{}),"\n",(0,l.jsx)(e.h2,{id:"knowledge-check-",children:"Knowledge Check \u2713"}),"\n",(0,l.jsxs)(e.ol,{children:["\n",(0,l.jsxs)(e.li,{children:[(0,l.jsx)(e.strong,{children:"Question 1"}),': Why is the "Credit Assignment Problem" harder with sparse rewards?']}),"\n",(0,l.jsxs)(e.li,{children:[(0,l.jsx)(e.strong,{children:"Question 2"}),": Which type of reward is easier to measure on a physical robot without external cameras: falling (sparse) or exact velocity (dense)?"]}),"\n",(0,l.jsxs)(e.li,{children:[(0,l.jsx)(e.strong,{children:"Question 3"}),": True or False: Dense rewards always lead to the optimal solution."]}),"\n"]}),"\n",(0,l.jsx)(e.hr,{}),"\n",(0,l.jsx)(e.h2,{id:"try-this",children:"Try This"}),"\n",(0,l.jsxs)(e.p,{children:["Modify your ",(0,l.jsx)(e.code,{children:"action_loop.py"})," to print ",(0,l.jsx)(e.em,{children:"both"})," rewards simultaneously."]}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"# Inside your loop\r\ndist = np.linalg.norm(state['position'] - target_pos)\r\nsparse = 1.0 if dist < 0.5 else 0.0\r\ndense = -dist\r\n\r\nprint(f\"Dist: {dist:.2f} | Sparse: {sparse} | Dense: {dense:.2f}\")\n"})}),"\n",(0,l.jsx)(e.p,{children:"Watch how the Dense signal fluctuates wildly with every random movement, giving information, while the Sparse signal sits dead at 0.0."}),"\n",(0,l.jsx)(e.hr,{}),"\n",(0,l.jsx)(e.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsxs)(e.li,{children:["Andrychowicz, M., et al. (2017). ",(0,l.jsx)(e.em,{children:"Hindsight Experience Replay"}),". NeurIPS. (A famous technique for learning from sparse rewards)."]}),"\n",(0,l.jsxs)(e.li,{children:["Ng, A. Y., et al. (1999). ",(0,l.jsx)(e.em,{children:"Policy invariance under reward transformations: Theory and application to reward shaping."})," ICML."]}),"\n"]})]})}function d(s={}){const{wrapper:e}={...(0,i.R)(),...s.components};return e?(0,l.jsx)(e,{...s,children:(0,l.jsx)(c,{...s})}):c(s)}},8453:(s,e,a)=>{a.d(e,{R:()=>t,x:()=>r});var n=a(6540);const l={},i=n.createContext(l);function t(s){const e=n.useContext(i);return n.useMemo(function(){return"function"==typeof s?s(e):{...e,...s}},[e,s])}function r(s){let e;return e=s.disableParentContext?"function"==typeof s.components?s.components(l):s.components||l:t(s.components),n.createElement(i.Provider,{value:e},s.children)}}}]);